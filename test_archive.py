#!/usr/bin/env python3
"""
å½’æ¡£åŠŸèƒ½æµ‹è¯•è„šæœ¬
æ¼”ç¤ºæ™ºèƒ½å½’æ¡£åŠŸèƒ½çš„å·¥ä½œåŸç†
"""

import os
import shutil
import json
from spotify import (
    create_archive_directory_structure,
    migrate_existing_archive_files,
    get_archive_statistics,
    extract_year_from_timestamp
)

def test_archive_functionality():
    """æµ‹è¯•å½’æ¡£åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å½’æ¡£åŠŸèƒ½")
    print("=" * 50)
    
    # 1. æµ‹è¯•æ—¶é—´æˆ³è§£æ
    print("\n1. æµ‹è¯•æ—¶é—´æˆ³è§£æåŠŸèƒ½ï¼š")
    test_timestamps = [
        "20250630_134002",
        "20240315_091530",
        "20230101_000000",
        "invalid_timestamp"
    ]
    
    for ts in test_timestamps:
        year = extract_year_from_timestamp(ts)
        print(f"   æ—¶é—´æˆ³: {ts} â†’ å¹´ä»½: {year}")
    
    # 2. åˆ›å»ºæµ‹è¯•å½’æ¡£ç›®å½•ç»“æ„
    print("\n2. åˆ›å»ºå½’æ¡£ç›®å½•ç»“æ„ï¼š")
    archive_dir = "archive"
    
    if not os.path.exists(archive_dir):
        os.makedirs(archive_dir)
        print(f"   âœ… åˆ›å»ºå½’æ¡£ç›®å½•: {archive_dir}")
    
    # åˆ›å»ºå¹´ä»½å­ç›®å½•
    for timestamp in ["20250630_134002", "20240315_091530"]:
        year_dir = create_archive_directory_structure(archive_dir, timestamp)
        print(f"   âœ… åˆ›å»ºå¹´ä»½ç›®å½•: {year_dir}")
    
    # 3. æ¨¡æ‹Ÿåˆ›å»ºä¸€äº›å½’æ¡£æ–‡ä»¶
    print("\n3. åˆ›å»ºæµ‹è¯•å½’æ¡£æ–‡ä»¶ï¼š")
    
    # åœ¨ 2025 ç›®å½•åˆ›å»ºæ–‡ä»¶
    test_file_2025 = os.path.join(archive_dir, "2025", "spotify_prices_all_countries_20250630_134002.json")
    test_data = {"test": "data", "year": 2025}
    
    with open(test_file_2025, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {test_file_2025}")
    
    # åœ¨ 2024 ç›®å½•åˆ›å»ºæ–‡ä»¶
    test_file_2024 = os.path.join(archive_dir, "2024", "spotify_prices_all_countries_20240315_091530.json")
    test_data = {"test": "data", "year": 2024}
    
    with open(test_file_2024, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {test_file_2024}")
    
    # 4. æµ‹è¯•å½’æ¡£ç»Ÿè®¡åŠŸèƒ½
    print("\n4. å½’æ¡£ç»Ÿè®¡ä¿¡æ¯ï¼š")
    stats = get_archive_statistics(archive_dir)
    print(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"   ğŸ“Š å¹´ä»½æ•°é‡: {len(stats['years'])}")
    
    for year, data in sorted(stats['years'].items(), reverse=True):
        print(f"   ğŸ“ {year}: {data['count']} ä¸ªæ–‡ä»¶")
        for file_path, mtime, filename in data['files'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"      - {filename}")
    
    # 5. æµ‹è¯•è¿ç§»åŠŸèƒ½ï¼ˆåˆ›å»ºä¸€äº›æ ¹ç›®å½•æ–‡ä»¶ç„¶åè¿ç§»ï¼‰
    print("\n5. æµ‹è¯•æ–‡ä»¶è¿ç§»åŠŸèƒ½ï¼š")
    
    # åœ¨æ ¹ç›®å½•åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
    root_test_file = os.path.join(archive_dir, "spotify_prices_all_countries_20230101_000000.json")
    test_data = {"test": "migration", "year": 2023}
    
    with open(root_test_file, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… åˆ›å»ºå¾…è¿ç§»æ–‡ä»¶: {root_test_file}")
    
    # æ‰§è¡Œè¿ç§»
    print("\n   å¼€å§‹æ‰§è¡Œè¿ç§»...")
    migrate_existing_archive_files(archive_dir)
    
    # æ£€æŸ¥è¿ç§»åçš„ç»Ÿè®¡
    print("\n6. è¿ç§»åçš„ç»Ÿè®¡ä¿¡æ¯ï¼š")
    stats = get_archive_statistics(archive_dir)
    print(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"   ğŸ“Š å¹´ä»½æ•°é‡: {len(stats['years'])}")
    
    for year, data in sorted(stats['years'].items(), reverse=True):
        print(f"   ğŸ“ {year}: {data['count']} ä¸ªæ–‡ä»¶")
    
    print("\nâœ… å½’æ¡£åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ å½’æ¡£åŠŸèƒ½è¯´æ˜ï¼š")
    print("   - æ‰€æœ‰å†å²æ•°æ®æ–‡ä»¶ä¼šè‡ªåŠ¨æŒ‰å¹´ä»½ç»„ç»‡åœ¨ archive/ ç›®å½•ä¸‹")
    print("   - æ¯æ¬¡è¿è¡Œçˆ¬è™«æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºå¯¹åº”å¹´ä»½çš„å­ç›®å½•")
    print("   - ç°æœ‰çš„å½’æ¡£æ–‡ä»¶ä¼šè‡ªåŠ¨è¿ç§»åˆ°æ­£ç¡®çš„å¹´ä»½ç›®å½•")
    print("   - æœ€æ–°çš„æ•°æ®ä¼šåŒæ—¶ä¿å­˜ä¸ºå¸¦æ—¶é—´æˆ³çš„å½’æ¡£ç‰ˆæœ¬å’Œlatestç‰ˆæœ¬")

if __name__ == "__main__":
    test_archive_functionality()
